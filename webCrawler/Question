
Problem 

Web Crawling is one of the important techniques used by data companies to scrap data. A web 
crawler searches the web pages starting from a given page and then crawls all the links 
available on that page. However, it never crawls the same page twice once initiated. The crawler 
uses two things to store data. One is a page queue which contains the list of all pages to be 
crawled and one is a crawled queue which contains the list of all pages that it has crawled up 
untill now. 

Example:
Google.co.in => contains two hyperlinks =>  facebook.com and twitter.com
Now the page queue and crawled queue is intially empty.
We insert Google.co.in in the page queue. 
The crawler crawls through Google.co.in and finds the above hyperlinks "facebok.com" and 
"twitter.com" and pushes them in the page queue. After it is done crawling, it pushes 
"Google.co.in" to crawled queue. 
Now there are two things in page queue=> facebook.com and twitter.com
The crawler now pops next element from page queue => facebook.com
Since, it has not yet crawled facebook.com, it crawls through facebook.com and does the same.

If the page queue is empty , the crawler does not crawl anything.
Now, this system needs to be implemented so that others can use our API.
Following APIs need to be implemented:

0.  void Init()
   {
      // called once before every test case
  }
1. void addUrl (char str[MAX_SIZE])
   {
     // add this url to page queue if not already present in page queue or not crawled yet
   }
2. void addHyperLink (char parent[MAX_SIZE], char child[MAX_SIZE])
   {
      // add child hyperlink to parent page
   }
3. void crawl()
   {
      // pop the front most page from page queue and crawl the page
   }
4. int queueSize()
   {
       // returns the size of page queue 
   }
5. int query (char str[MAX_SIZE])
   {
       // returns the number of pages in crawled queue which has str as prefix 
   }

Sample Input/Output:
1
 

7
 3
 number of commands and number of return queries
 
1
 google
 insert "google" into page queue
 
1
 facebook
 insert "facebook" into page queue
 
2
 google twitter
 add "twitter" as a hyperlink in "google"
 
3
 
 crawls first page "google" as it is not present in crawled queue , adds hyperlink "twitter" to page queue as it is not present in page queue
 
4
 2
 
4th API returns queueSize of page queue which is 2 => {facebook,twitter}

 
5
 go 1
 
5th API returns number of strings with "go" as a prefix in crawled queue {google}, and google has prefix "go"

 

 
 
 




Constraints:



Total Number of API Calls/Commands: <=50000
Length of any website/string in APIs <=26



Note: At any moment of time . no string should be present in page queue or crawled queue more than once. And no string should be present in both of them. 


At any time, at most one page will be crawled.
